Data lakehouse systems are increasingly becoming the primary choice for running analytics in large companies with over 1000 employees \cite{StateDataLakehouse2024}. The data lakehouse architecture \cite{lakehouse2021} is preferred over old paradigms, i.e., data warehouses and data lakes, as it builds upon the advantages of both systems, having the scalability properties of data lakes while preserving the \gls{ACID} properties typical of data warehouses \cite{lakehouse2021}. Additionally, data lakehouse systems include partitioning, which reduces query complexity significantly and provides "time travel" capabilities, enabling users to access different versions of data, versioned over time \cite{crociDataLakehouseHype2022}.

Three main implementations of this paradigm emerged over time \cite{ApacheHudiVs}: 
\begin{enumerate}
    \item \textbf{Apache Hudi}: first introduced by Uber \cite{rajaperumalUberEngineeringIncremental2017}, and now primarily backed by Uber, Tencent, Alibaba, and Bytedance.
    \item \textbf{Apache Iceberg}: first introduced by Netflix, and now primarily backed by Netflix, Apple, and Tencent.
    \item \textbf{Delta Lake}: first introduced by Databricks \cite{armbrustDeltaLakeHighperformance2020}, and now primarily backed by Databricks and Microsoft.
\end{enumerate}

While large communities support all three projects, Delta Lake is acknowledged as the de-facto data lakehouse solution \cite{ApacheHudiVs}. This recognition is mainly thanks to Databricks, which first promoted this new architecture over data lakes among their clients around 2020 \cite{armbrustDeltaLakeHighperformance2020}.

As a data query and processing engine, Delta Lake is typically used with Apache Spark \cite{zahariaApacheSparkUnified2016}. This approach is practical when processing large quantities of data (1 TB or more) in the cloud, but whether this approach is effective on a small scale (1 GB - 100 GB) remains to be investigated \cite{Khazanchi1801362}.

DuckDB~\cite{raasveldtDuckDBEmbeddableAnalytical2019}, a \gls{DBMS} and Polars~\cite{vinkWroteOneFastest2021}, a DataFrame library, highlighted the limitations of Apache Spark. When processing data locally with smaller volumes, an Apache Spark cluster underperforms compared to other alternatives. This result ultimately increases costs and computation time when using Spark~\cite{BenchmarkResultsSpark,ebergenUpdatesH2OAi2023}.

Another important consideration is that Python, due to its simplicity and high level of abstraction, has emerged as the most widely used programming language in the field of data science \cite{nagpalPythonDataAnalytics2019}. Python is currently the most popular general-purpose programming language \cite{TIOBEIndex, StackOverflowDeveloper}, and it is by far the most used language for \gls{ML} and \gls{AI} applications \cite{python-machine-learning}; this is mainly thanks to its strong abstraction capabilities and accessibility. This trend can also be observed by looking at the most popular libraries among developers, where two Python libraries make the podium: NumPy and Pandas \cite{StackOverflowDeveloper}.
In this scenario, using a Python client for Delta Lake would be beneficial as developers would not have to resort to Apache Spark and its Python \gls{API} (PySpark). This approach with small-scale (1 GB - 100 GB) use cases would improve performance significantly.

This native Python access for Delta Lake directly benefits Hopsworks \gls{AB}, the host company of this master thesis. Hopsworks \gls{AB} develops a homonymous feature store for \gls{ML}. This centralized, collaborative data platform enables the storage and access of reusable features~\footnote{Definition from the company's website at \url{https://www.hopsworks.ai/}}. This architecture also supports point-in-time correct datasets from historical feature data \cite{Pettersson1695672}.

This presented project aims to reduce the latency (seconds) and thus increase the data throughput (rows/second) for reading and writing on Delta Lake tables that act as an offline feature store in Hopsworks. Currently, the writing pipeline is Apache Spark-based, and the fundamental hypothesis of the project is that a faster non-Apache Spark alternative is possible. If successful, Hopsworks AB will consider incorporating this system into the open-source Hopsworks feature store, significantly enhancing the experience for Python users working with smaller datasets (1 GB - 100 GB). More generally, this work will outline the possibility of Apache Spark alternatives in small-scale use cases.

This thesis's main contributions are the following:
\begin{itemize}
    \item Two code implementations adding support for \gls{HDFS} and \gls{HopsFS} in the delta-rs library. Of these, the first one is incomplete, as the second was preferred according to the consistency and maintainability requirements defined in Section \ref{subsec:requirements}. These code contributions are more than two thousand \gls{LOC} for the first implementation and eight hundred for the second. Note that while these metrics might provide some insight into the contribution's value, this work's true value is in creating a production-ready solution that correctly navigates a complex data stack of technologies with intricate dependencies, answering all requirements. The most relevant recognition of this contribution is the inclusion of this code implementation in a production environment in the Hopsworks feature store shortly after the thesis publication.
    \item The experiments' results detail the difference in performance between the newly implemented system and the legacy system in read and write operations expressed as latency and throughput. Experiments were also performed at different \gls{CPU} configurations and table sizes fifty times, enabling a confidence interval estimate. Results report that the new system using the delta-rs library to access data has a latency reduction compared to the legacy system from ten up to forty times in write operations and from forty-seven percent up to forty times in read operations. These results are a solid contribution to the data management field, confirming present research on the limitations of using Spark with small amounts of data. Additionally, the value of this work consists of the large number of experiments conducted in a well-defined environment, which enables reproducible results using the code made available in this thesis.
\end{itemize}