\markboth{\abstractname}{}
\begin{scontents}[store-env=lang]
ita
\end{scontents}
\begin{scontents}[store-env=abstracts,print-env=true]
La necessità di costruire modelli di \textit{Machine Learning (ML)} basati su quantità sempre maggiori di dati ha posto nuove sfide ai sistemi di gestione dei dati. I \textit{feature stores} sono emersi come una soluzione efficace per consentire il riutilizzo delle \textit{features}, organizzando al contempo le trasformazioni dei dati e garantendo la coerenza tra il \textit{feature engineering}, il \textit{training} e l'\textit{inference} dei modelli. Recenti pubblicazioni dimostrano che il \textit{feature store} di Hopsworks presenta metriche di prestazione superiori sia per quanto riguarda il \textit{training} dei modelli sia per quanto riguarda le \textit{query} di \textit{online inference}, rispetto alle alternative esistenti basate su \textit{cloud}. In questo sistema, la latenza per eseguire un'operazione di scrittura è di almeno uno o più minuti, anche per piccole quantità di dati (1 GB o meno). Si ritiene che questo limite sia specifico di Spark, che il sistema utilizza per scrivere i dati sull'\textit{offline feature store}. Questa ipotesi è già stata confermata nel caso della latenza in lettura, dove la scelta di un'alternativa a Spark, ovvero un server Arrow Flight e DuckDB, ha migliorato notevolmente le prestazioni. Un approccio promettente sembra essere l'adozione di una nuova soluzione per la gestione dei dati, Delta Lake, e l'accesso ad essa tramite una libreria Rust chiamata delta-rs. Questa tesi studia la possibilità di ridurre la latenza di lettura e scrittura nell' \textit{offline feature store}  espandendo la libreria delta-rs per supportare il \textit{file system} del \textit{feature store} di Hopsworks, chiamato HopsFS, e valutando in modo comparativo le prestazioni del sistema precedente e di quello appena implementato. Dopo la prima fase di implementazione iterativa del sistema basata su requisiti fissati, il sistema è stato valutato eseguendo e misurando le operazioni di lettura e scrittura in quattro diverse configurazioni di CPU, aumentando il numero di core della CPU fino a otto. Gli esperimenti sono stati eseguiti cinquanta volte per stimare un intervallo di confidenza che permettesse un'accurata valutazione comparativa dei sistemi. I risultati hanno confermato la superiorità della libreria delta-rs rispetto al sistema Spark in tutte le operazioni di scrittura, con una riduzione di dieci volte della latenza. Delta-rs ha anche superato il sistema alternativo a Spark usato nelle operazioni di lettura, con una riduzione di dieci volte della latenza in tutti gli esperimenti tranne in quello con la tabella più grande (60 milioni di righe), dove il miglioramento è di un fattore minore. Questi risultati incoraggiano la ricerca futura di alternative a Spark per l'ottimizzazione delle prestazioni nei sistemi di gestione dei dati su piccola scala (1 GB - 100 GB).
\end{scontents}
\subsection*{Parole chiave}
\begin{scontents}[store-env=keywords,print-env=true]
Machine Learning, Feature Store, Limitazione specifica di Spark, Delta Lake, libreria delta-rs, Latenza di lettura/scrittura
\end{scontents}